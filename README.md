# 🖐️ Gesture-Controlled Virtual Keyboard and Mouse Using Machine Learning

This project implements a **virtual keyboard and mouse system controlled through hand gestures**. Using computer vision and machine learning, the system captures real-time video input, detects hand movements, and maps them to mouse and keyboard actions—enabling hands-free interaction with a computer.

---

## 🎯 Objective

To create a gesture-based input system that allows users to control the mouse and type on a virtual keyboard using only their hands, without physical contact. This is useful for accessibility, touchless interfaces, and futuristic human-computer interaction (HCI).

---

## ✨ Key Features

- Hand gesture recognition using webcam input
- Real-time virtual mouse control (move, click, scroll)
- Virtual keyboard interaction using finger positioning
- Customizable gestures and actions
- Built using OpenCV and MediaPipe for hand tracking

---

## 🧠 Technologies & Tools

- Python
- OpenCV
- MediaPipe (for hand landmark detection)
- PyAutoGUI (to simulate keyboard/mouse)
- NumPy, time, math, etc.

---

## 🚀 Getting Started

### 1. Clone the Repository

```bash
git clone https://github.com/Ashwini-Manohar/Gesture-Controlled-Virtual-Keyboard-and-Mouse-Using-Machine-Learning.git
cd Gesture-Controlled-Virtual-Keyboard-and-Mouse-Using-Machine-Learning

2. Install Requirements

Make sure Python is installed, then run:
pip install -r requirements.txt

Or manually install key dependencies:
pip install opencv-python mediapipe pyautogui numpy

3. Run the System
python main.py
